library(tidyverse)
library(dplyr)
library(caret)
library(ModelMetrics)
library(randomForest)
library(stringr)
library(xgboost)  # for fitting GBMs
library(ranger)   # for fitting random forests
library(rpart) 
library(patchwork)
library(DataExplorer)

rm(list=ls())

getwd()

setwd("D:/Non_Documents/AI/R/data")
dir()


df <- read.csv("Ag_paste.csv", stringsAsFactors=T)

df <- tibble::tribble(
  ~Ag.Type.1, ~Ag.Type.2, ~Ag.Type.3, ~Ag.Type.4, ~Paste.내.Ag.함량, ~Ag.Type.1.1, ~Ag.Type.2.1, ~Ag.Type.3.1, ~Ag.Type.4.1, ~Resin.A, ~Resin.B, ~Resin.C, ~Resin.D, ~Resin.E, ~Paste.내.Resin.함량, ~첨가제.1, ~첨가제.2, ~Solvent.1, ~Paste.내.Sovent.함량, ~Viscocity..cp., ~R_200.,
         0.6,        0.1,        0.1,          0,          0.785,        0.471,       0.0785,       0.0785,            0,    0.065,        0,        0,        0,        0,             0.065,   0.01,      0,        0.1,               0.14,           2644L,    13.3,
         0.5,        0.2,        0.1,          0,          0.745,       0.3725,        0.149,       0.0745,            0,    0.065,        0,        0,        0,        0,             0.065,   0.01,      0,       0.14,               0.18,           2795L,     8.6,
         0.5,        0.2,        0.1,          0,          0.745,       0.3725,        0.149,       0.0745,            0,    0.065,        0,        0,        0,        0,             0.065,  0.005,  0.005,       0.14,               0.18,           2450L,     7.9,
         0.5,        0.2,        0.1,          0,          0.745,       0.3725,        0.149,       0.0745,            0,     0.05,    0.015,        0,        0,        0,             0.065,  0.005,  0.005,       0.14,               0.18,           2329L,    22.5,
         0.5,        0.2,        0.1,          0,           0.75,        0.375,         0.15,        0.075,            0,     0.04,        0,     0.02,        0,        0,              0.06,  0.005,  0.005,       0.14,               0.18,           3518L,    56.5,
         0.5,        0.2,        0.1,          0,          0.752,        0.376,       0.1504,       0.0752,            0,     0.03,        0,    0.028,        0,        0,             0.058,  0.005,  0.005,       0.14,               0.18,           3984L,     330,
         0.3,        0.2,        0.1,        0.2,          0.745,       0.2235,        0.149,       0.0745,        0.149,    0.065,        0,        0,        0,        0,             0.065,  0.005,  0.005,       0.14,               0.18,           2573L,    1520,
         0.5,        0.2,        0.1,          0,           0.77,        0.385,        0.154,        0.077,            0,     0.02,     0.02,        0,        0,        0,              0.04,  0.005,  0.005,       0.14,               0.18,           4622L,    51.9,
         0.5,        0.2,        0.1,          0,           0.75,        0.375,         0.15,        0.075,            0,     0.03,        0,        0,     0.03,        0,              0.06,  0.005,  0.005,       0.14,               0.18,           7505L,     516,
         0.3,        0.2,        0.3,          0,          0.745,       0.2235,        0.149,       0.2235,            0,    0.065,        0,        0,        0,        0,             0.065,      0,   0.01,       0.14,               0.18,           2118L,     232,
         0.5,        0.2,        0.1,          0,          0.755,       0.3775,        0.151,       0.0755,            0,    0.045,     0.01,        0,        0,        0,             0.055,      0,   0.01,       0.14,               0.18,           3339L,    45.4,
         0.5,        0.2,        0.1,          0,          0.753,       0.3765,       0.1506,       0.0753,            0,    0.045,        0,        0,        0,    0.012,             0.057,      0,   0.01,       0.14,               0.18,           3140L,    75.6,
         0.3,        0.2,        0.3,          0,          0.745,       0.2235,        0.149,       0.2235,            0,    0.065,        0,        0,        0,        0,             0.065,      0,   0.01,       0.14,               0.18,           3288L,    81.4,
         0.3,        0.2,        0.3,          0,          0.753,       0.2259,       0.1506,       0.2259,            0,    0.045,        0,        0,        0,    0.012,             0.057,      0,   0.01,       0.14,               0.18,           3167L,     7.5
  )


head(df)
clipr::write_clip(df)
str(df)
summary(df)


## 데이터 대강 보기

pairs(df) ## 간단히 상관관계 보기


library(WVPlots)
PairPlot(df, colnames(df)[1:26], title = "Ag_paste_resistance",
         group_var = NULL, palette="Dark2",point_color = "darkgray") 

############### GGally 패키지를 이용한 EDA  ##############################

library(GGally)

#create pairs plot
ggpairs(df)


df <- df[,-c(5,19,21)] #한종류만 있는 열은 제거
str(df)
df <- df[,-c(21,23)] #target 이외 Y 제거
df <- df[-7, ] #이상치 제거

#모델 만들기
str(df)

m1<-train(R_200.~., data=df, method="glm") #1로지스틱 회귀 모델
m2<-randomForest(R_200.~., data=df, ntree=100) #2랜덤포레스트 모델

# Fit a single regression tree
tree <- rpart(R_200. ~ ., data = df) #3의사결정나무

# Fit a random forest
set.seed(101)
rfo <- ranger(R_200. ~ ., data = df, importance = "impurity") #5빠른 랜덤포레스트

# Fit a GBM
set.seed(102)
bst <- xgboost(
  data = data.matrix(subset(df, select = -R_200.)),
  label = df$R_200., 
  objective = "reg:linear",
  nrounds = 100, 
  max_depth = 5, 
  eta = 0.3,
  verbose = 0  # suppress printing
)



# VI plot for single regression tree
vi_tree <- tree$variable.importance
barplot(vi_tree, horiz = TRUE, las = 1)

# VI plot for RF
vi_rfo <- rfo$variable.importance %>% sort()
barplot(vi_rfo, horiz = TRUE, las = 1)

# VI plot for GMB
library(Ckmeans.1d.dp)
vi_bst <- xgb.importance(model = bst)
xgb.ggplot.importance(vi_bst)

library(vip)
i1 <- vip(m1) + ggtitle("Logistic regression")
i2 <- vip(m2)+ ggtitle("Random Forest")
#i3 <- vip(tree)+ ggtitle("Descision tree")
i4 <- vip(rfo)+ggtitle("Fast Random Forest")
i5 <- vip(bst)+ggtitle("XGBoost")

i1+i5+i2+i4


#예측하기

p1<-predict(m1, df)
p2<-predict(m2, df)
#p3<-predict(tree, df)
p4<- predict(rfo, data = df, predict.all = TRUE)
p4 <- p4$predictions[,2]

p5<-predict(bst, data.matrix(df[,-21]))


#평가하기

r1 <- caret::R2(df$R_200., p1) #로지스틱 회귀분석
r2 <- caret::R2(df$R_200., p2) #랜덤포레스트
#r3 <- caret::R2(df$R_200., p3) #의사결정나무
r4 <- caret::R2(df$R_200., p4) #ranger
r5 <- caret::R2(df$R_200., p5) #xgboost

plot(df$R_200., p1)
plot(df$R_200., p2)
plot(df$R_200., p4)
plot(df$R_200., p5)


name <- c("Logistic regression", "Random Forest", "Fast Random Forest","XGBoost")
r_squre <- round(c(r1,r2,r4,r5),2)
v <- as.data.frame(cbind(name, r_squre) )

v %>% 
  mutate(name = fct_reorder(name,desc(r_squre))) %>% 
  ggplot(aes(name, r_squre, fill=name))+geom_col() + 
  geom_text(data = v, aes(label = paste("R2=",r_squre)), y = r_squre, size=5)+
  ggtitle("Resistance of Ag paste ")+
  labs(y="R^2", x="M/L Models",subtitle="data by Won Pro")+
  theme_bw()+
  theme(axis.text.y = element_text(size=12), 
        axis.text.x = element_text(size=12))+
  theme(legend.position="none")

